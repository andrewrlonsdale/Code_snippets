import os
import json
import re
import csv
from prettytable import PrettyTable

# Define the table name to search for
table_name = ""

# Set the root directory to search for notebooks (adjust as needed)
root_dir = ""

# Initialize a total count of cells with matches
total_matches = 0

# Create a table for displaying results
results_table = PrettyTable()
results_table.field_names = ["Notebook", "Cell Number", "Match Type", "Content Snippet"]

# List to store results for CSV output
csv_results = []

def reconstruct_vertical_text(vertical_text):
    """
    Reconstruct vertically aligned text into horizontal text.
    Each column of characters is joined to form a horizontal string.
    """
    lines = vertical_text.splitlines()
    if not lines:
        return ""
    max_length = max(len(line) for line in lines)
    reconstructed = ""
    for i in range(max_length):
        for line in lines:
            if i < len(line):
                reconstructed += line[i]
        reconstructed += " "  # Add space between reconstructed words
    return reconstructed.strip()

def clean_snippet(snippet):
    """
    Clean the content snippet by removing Markdown, HTML, and CSS.
    """
    # Remove HTML tags
    snippet = re.sub(r"<[^>]+>", "", snippet)
    # Remove Markdown links (e.g., [text](url)) and preserve only the text
    snippet = re.sub(r"\[([^\]]+)\]\([^)]+\)", r"\1", snippet)
    # Remove Markdown headers (e.g., # Header, ## Header)
    snippet = re.sub(r"^#{1,6}\s+", "", snippet, flags=re.MULTILINE)
    # Remove Markdown emphasis and inline code formatting (e.g., **bold**, *italic*, `code`, __underline__, ~~strike~~)
    snippet = re.sub(r"(\*\*|\*|__|_|`|~~)", "", snippet)
    # Remove Markdown blockquotes and list markers (e.g., >, -, *)
    snippet = re.sub(r"(^|\n)[>\-\*]\s+", r"\1", snippet)
    # Remove CSS or inline style declarations within curly braces
    snippet = re.sub(r"{[^}]+}", "", snippet)
    # Remove extra whitespace
    snippet = re.sub(r"\s+", " ", snippet).strip()
    return snippet

# Walk through all files and subdirectories starting from root_dir
for dirpath, dirnames, filenames in os.walk(root_dir):
    for filename in filenames:
        # Process only Jupyter Notebook files
        if filename.endswith(".ipynb"):
            notebook_path = os.path.join(dirpath, filename)
            try:
                with open(notebook_path, "r", encoding="utf-8") as nb_file:
                    notebook = json.load(nb_file)
            except Exception as e:
                print(f"Error reading notebook {notebook_path}: {e}")
                continue

            # Use enumerate to count cells in the notebook correctly (starting from 1)
            for cell_index, cell in enumerate(notebook.get("cells", []), start=1):
                # Initialize a set for match types and list for snippets for this cell
                combined_match_types = set()
                combined_snippets = []

                # Check cell source (for code or markdown cells)
                cell_source = "".join(cell.get("source", []))
                if table_name in cell_source:
                    combined_match_types.add("Source")
                    combined_snippets.append("Source:\n" + clean_snippet(cell_source))

                # Check cell outputs if available
                for output in cell.get("outputs", []):
                    if "text" in output:
                        output_text = "".join(output.get("text", []))
                        reconstructed_text = reconstruct_vertical_text(output_text)
                        if table_name in output_text:
                            combined_match_types.add("Horizontal Output")
                            combined_snippets.append("Horizontal Output:\n" + clean_snippet(output_text))
                        elif table_name in reconstructed_text:
                            combined_match_types.add("Output (Text)")
                            combined_snippets.append("Output (Text):\n" + clean_snippet(output_text))
                    if "data" in output:
                        for key, value in output.get("data", {}).items():
                            if isinstance(value, list):
                                output_data = "".join(value)
                            else:
                                output_data = str(value)
                            reconstructed_data = reconstruct_vertical_text(output_data)
                            if table_name in output_data:
                                combined_match_types.add("Horizontal Output")
                                combined_snippets.append("Horizontal Output (data):\n" + clean_snippet(output_data))
                            elif table_name in reconstructed_data:
                                combined_match_types.add("Output (Data)")
                                combined_snippets.append("Output (Data):\n" + clean_snippet(output_data))

                # If the cell contains any match, add one row to the table and CSV
                if combined_snippets:
                    match_type_str = ", ".join(sorted(combined_match_types))
                    # Join multiple snippets with a separator for clarity
                    cell_snippets = "\n\n---\n\n".join(combined_snippets)
                    results_table.add_row([notebook_path, cell_index, match_type_str, cell_snippets])
                    csv_results.append([notebook_path, cell_index, match_type_str, cell_snippets])
                    total_matches += 1

# Display the results table
if total_matches > 0:
    print(results_table)
else:
    print(f"No occurrences of '{table_name}' found in any notebook.")

# Save results to a CSV file
csv_file_path = "results.csv"
with open(csv_file_path, "w", newline="", encoding="utf-8") as csv_file:
    writer = csv.writer(csv_file)
    writer.writerow(["Notebook", "Cell Number", "Match Type", "Content Snippet"])
    writer.writerows(csv_results)

print(f"\nResults have been saved to '{csv_file_path}'.")
print(f"\nTotal number of cells with '{table_name}': {total_matches}")
