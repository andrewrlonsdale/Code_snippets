import os
import datetime
import awswrangler as wr

# Define the paths for the folders
input_folder = '/path/to/input/folder'
completed_folder = os.path.dirname(os.path.abspath(__file__))
log_folder = os.path.join(completed_folder, 'Log')

# Create the Log folder if it doesn't exist
if not os.path.exists(log_folder):
    os.makedirs(log_folder)

# Get the current date to add to the log filename
date_today = datetime.datetime.now().strftime("%Y-%m-%d")

# Create the log filename with the current date
log_filename = os.path.join(log_folder, f"{date_today}.log")

# Open the log file in append mode to add new runs
with open(log_filename, "a") as log_file:
    # Get a list of files in the input folder
    files = os.listdir(input_folder)
    
    # Loop through each file and create a table in AWS
    for file in files:
        try:
            # Create the table name from the file name
            table_name = os.path.splitext(file)[0]
            
            # Create the full path to the input file
            input_path = os.path.join(input_folder, file)
            
            # Create the full path to the completed file
            completed_path = os.path.join(completed_folder, file)
            
            # Create the table in AWS
            wr.s3.to_parquet(input_path, f"aws://my-bucket/{table_name}")
            
            # Move the file to the completed folder
            os.rename(input_path, completed_path)
            
            # Write to the log file that the table was created
            log_file.write(f"{table_name} table was created from {file}\n")
            
        except Exception as e:
            # Write to the log file that there was an error
            log_file.write(f"Error creating table from {file}: {e}\n")
            
            # Move the file back to the input folder
            os.rename(completed_path, input_path)
            
            
            
            files = [file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]
            
            
            
            
            
            
            
            
            
            
            
            
            
import os
import datetime
import awswrangler as wr

folder_path = "path/to/folder"  # Replace with the actual folder path

# Check if the folder exists
if not os.path.exists(folder_path):
    print("Folder does not exist!")
    exit()

# Get a list of files in the folder
files = [file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]

# Check if there are any files in the folder
if len(files) > 0:
    print("Files found in the folder:")
    for file_name in files:
        print(file_name)

    # Create a subfolder called "complete" if it doesn't exist
    complete_folder_path = os.path.join(folder_path, "complete")
    if not os.path.exists(complete_folder_path):
        os.makedirs(complete_folder_path)

    # Create a log file
    log_file_path = os.path.join(folder_path, "log.txt")

    # Move files to the "complete" subfolder and create tables in AWS
    with open(log_file_path, "a") as log_file:
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_file.write(f"Log created at: {current_time}\n")
        log_file.write("Files processed:\n")
        for file_name in files:
            file_path = os.path.join(folder_path, file_name)
            new_file_path = os.path.join(complete_folder_path, file_name)

            try:
                # Move the file to the "complete" subfolder
                os.rename(file_path, new_file_path)
                log_file.write(f"{file_name} - moved\n")

                # Create a table in AWS using AWS Wrangler
                table_name = os.path.splitext(file_name)[0]
                wr.s3.to_parquet(new_file_path, f"my-bucket/{table_name}.parquet", index=False)
                log_file.write(f"{table_name} - table created in AWS\n")
            except Exception as e:
                log_file.write(f"{file_name} - error occurred\n")
                log_file.write(f"Error details: {str(e)}\n")

                # If an error occurs, move the file back to the original folder
                os.rename(new_file_path, file_path)
                log_file.write(f"{file_name} - moved back to original folder\n")

    print("Files processed.")
    print(f"Log file created: {log_file_path}")
else:
    print("No files found in the folder.")
            
            
            
            
            
            
            
import pandas as pd

# Read the CSV file into a DataFrame
df = pd.read_csv('your_file.csv')

# Specify the filename
filename = 'your_filename.csv'

# Find the row where 'filename' is located
row = df[df['Column_Name_For_Filename'] == filename]

# Check if the row exists
if not row.empty:
    # Get the adjacent column value in the row
    adjacent_value = row['Adjacent_Column_Name'].values[0]
    print(adjacent_value)
else:
    print("Filename not found in the CSV file.")

            
            
duplicates = new_rows[new_rows.duplicated()]
if not duplicates.empty:
    print("Duplicate rows found in the new data. Please remove them and try again.")
    # Optionally, you can choose to handle duplicates based on your requirements.

# Check if values already exist in the DataFrame
existing_values = df[df['Column1'].isin(new_rows['Column1']) & df['Column2'].isin(new_rows['Column2'])]
if not existing_values.empty:
    print("Some values already exist in the CSV file. Please remove them from the new data and try again.")
    # Optionally, you can choose to handle existing values based on your requirements.

            
            
new_rows = new_rows[~new_rows.duplicated()]
new_rows = new_rows[~(new_rows['Column1'].isin(df['Column1']) & new_rows['Column2'].isin(df['Column2']))]
       
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
