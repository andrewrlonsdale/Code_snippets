import os
import json
import pandas as pd
import re
from collections import Counter
from openpyxl import load_workbook

notebook_dir = "path_to_your_notebooks"

found_queries = []
variable_frequencies = Counter()


def extract_variables_from_query(query):
    """Extract table names from 'FROM <table>' usage."""
    tables = re.findall(r"FROM\s+([a-zA-Z_][a-zA-Z0-9_\.]*)", query, re.IGNORECASE)
    for table in tables:
        variable_frequencies[table] += 1


def strip_quotes(s):
    """
    Remove surrounding triple or single/double quotes if present.
    Also trims leading f/r/b/u if you are using f-strings or raw strings.
    """
    s = s.strip()
    
    # Remove optional prefix like f, r, fr, rf, etc.
    # e.g. f"""some text""", r'some text'
    s = re.sub(r'^[frbuFRBU]+', '', s)

    # Check triple quotes first
    triple_quotes = ['"""', "'''"]
    for tq in triple_quotes:
        if s.startswith(tq) and s.endswith(tq):
            return s[len(tq):-len(tq)].strip()

    # Fall back to single/double quotes
    if (s.startswith('"') and s.endswith('"')) or (s.startswith("'") and s.endswith("'")):
        return s[1:-1].strip()

    return s  # If not wrapped in quotes, just return


def extract_sql_statements_in_cell(cell_source):
    """
    1) Extract 'SELECT ...' lines from raw code (ends with ; or cell boundary).
    2) Extract queries from calls like:
       pd.read_sql_query("..."), spark.sql("""...""".format(...)), etc.
       allowing optional .format(...) at the end of the string.
    """

    queries = []

    # ----------------------------------------------------------------
    # 1) RAW SQL: "SELECT ... up to ; or end-of-string"
    # ----------------------------------------------------------------
    raw_sql_pattern = re.compile(
        r'(?i)SELECT\b(.*?)(?=(;|$))',  # case-insensitive
        re.DOTALL
    )
    for match in raw_sql_pattern.finditer(cell_source):
        sql_text = "SELECT" + match.group(1)
        sql_text = sql_text.rstrip(" ;\t\r\n")
        if "SELECT" in sql_text.upper():
            queries.append(sql_text)

    # ----------------------------------------------------------------
    # 2) FUNCTION CALLS: e.g. pd.read_sql_query("SELECT ...".format(...))
    #    or spark.sql("""SELECT ...""")
    # ----------------------------------------------------------------
    # We capture the string literal in group 'query_str', ignoring the optional .format(...) 
    # that may appear right after the quoted string. Example:
    #   spark.sql("""SELECT * FROM table WHERE x = {}""".format(x))
    #   pd.read_sql_query("SELECT ...".format(...))
    func_pattern = re.compile(
        r'(?:pd|pandas|wr\.athena|spark)\.'       # library name
        r'(?:read_sql_query|sql)\(\s*'             # function call
        r'(?P<query_str>'                          # CAPTURE group
            # triple-quoted strings (with optional f/r prefixes)
            r'(?:[frbuFRBU]*"""[\s\S]*?""")'
            r'|'
            r'(?:[frbuFRBU]*\'\'\'[\s\S]*?\'\'\')'
            r'|'
            # single/double-quoted strings
            r'(?:[frbuFRBU]*"[^"]*")'
            r'|'
            r'(?:[frbuFRBU]*\'[^\']*\')'
        r')'
        # optional .format(...) call
        r'(?:\.format\s*\([^)]*\))
