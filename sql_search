import os
import json
import re
import pandas as pd
from collections import defaultdict, Counter
from openpyxl import load_workbook

notebook_dir = "path_to_your_notebooks"

table_frequencies = Counter()
column_frequencies = defaultdict(Counter)
found_queries = []

# --------------------------------------------------------------------
# 1. Parsing Utilities
# --------------------------------------------------------------------

def strip_quotes(s):
    """
    Remove surrounding triple or single/double quotes if present,
    as well as optional f/r/b/u prefixes (f-strings, raw strings, etc.).
    """
    s = s.strip()
    # Remove prefix like f, r, fr, rf, etc.
    s = re.sub(r'^[frbuFRBU]+', '', s)

    # Check triple quotes first
    triple_quotes = ['"""', "'''"]
    for tq in triple_quotes:
        if s.startswith(tq) and s.endswith(tq):
            return s[len(tq):-len(tq)].strip()

    # Fall back to single or double quotes
    if (s.startswith('"') and s.endswith('"')) or (s.startswith("'") and s.endswith("'")):
        return s[1:-1].strip()

    return s

def parse_columns_from_select(sql_text):
    """
    Naively extract columns between SELECT and FROM.
    e.g., SELECT col1, col2 FROM table
    Returns a list of columns or empty list if not found or if '*' is used.
    """
    match = re.search(r'(?i)SELECT\s+(.*?)\s+FROM\s+', sql_text)
    if not match:
        return []
    col_str = match.group(1).strip()
    if '*' in col_str:
        return []
    return [c.strip() for c in col_str.split(',') if c.strip()]

def parse_table_from_query(sql_text):
    """
    Extract the first table name from 'FROM table_name'.
    Return 'Unknown' if none found.
    """
    match = re.search(r'(?i)\bFROM\s+([a-zA-Z_][a-zA-Z0-9_.]*)', sql_text)
    return match.group(1) if match else "Unknown"

def extract_format_arguments(format_snippet):
    """
    Given a format snippet like: .format(db_in="my_db", table_out="my_table")
    extract named arguments as a dict: {"db_in": "my_db", "table_out": "my_table"}.
    Note: only handles string literals key="value" or key='value'.
    """
    # Example snippet: .format(db_in="my_db", table_out="my_table")
    # Remove '.format' and parentheses
    inside_parens_match = re.search(r'\.format\s*\((.*)\)', format_snippet, re.DOTALL)
    if not inside_parens_match:
        return {}
    
    args_str = inside_parens_match.group(1)
    # Regex for key="value" or key='value'
    kv_pattern = re.compile(r'(\w+)\s*=\s*["\']([^"\']*)["\']')
    found = kv_pattern.findall(args_str)
    return {k: v for k, v in found}

# --------------------------------------------------------------------
# 2. SQL Extraction
# --------------------------------------------------------------------

def extract_sql_statements_in_cell(cell_source):
    """
    Returns a list of tuples: (sql_statement, format_snippet)
      - sql_statement: the raw or stripped SELECT statement
      - format_snippet: the entire '.format(...)' if present, else ''
    
    We do two passes:
      1) Raw SQL queries (SELECT ... ; or end-of-cell)
      2) Function calls to pd.read_sql_query or spark.sql
         capturing the optional .format(...) snippet separately.
    """
    results = []

    # 2.1) Raw SQL
    raw_sql_pattern = re.compile(
        r'(?i)SELECT\b(.*?)(?=(;|$))',
        re.DOTALL
    )
    for match in raw_sql_pattern.finditer(cell_source):
        sql_text = "SELECT" + match.group(1)
        sql_text = sql_text.rstrip(" ;\t\r\n")
        if "SELECT" in sql_text.upper():
            # No .format(...) snippet for raw queries
            results.append((sql_text, ""))

    # 2.2) Function calls
    # We add a capturing group for .format(...) => (?P<format_str>\.format\s*\([^)]*\))?
    func_pattern = re.compile(
        r'(?:pd|pandas|wr\.athena|spark)\.'        # library
        r'(?:read_sql_query|sql)\(\s*'             # function
        r'(?P<query_str>'
            # triple-quoted strings
            r'(?:[frbuFRBU]*"""[\s\S]*?""")'
            r'|'
            r'(?:[frbuFRBU]*\'\'\'[\s\S]*?\'\'\')'
            r'|'
            # single/double-quoted
            r'(?:[frbuFRBU]*"[^"]*")'
            r'|'
            r'(?:[frbuFRBU]*\'[^\']*\')'
        r')'
        r'(?P<format_str>\.format\s*\([^)]*\))?'  # capturing the optional .format(...) snippet
        r'\s*\)',
        re.DOTALL
    )
    for match in func_pattern.finditer(cell_source):
        raw_sql = match.group('query_str')
        format_piece = match.group('format_str') or ''
        clean_sql = strip_quotes(raw_sql)
        if 'SELECT' in clean_sql.upper():
            results.append((clean_sql, format_piece))

    return results

# --------------------------------------------------------------------
# 3. Main Notebook Parsing
# --------------------------------------------------------------------

for root, _, files in os.walk(notebook_dir):
    for file in files:
        if file.endswith(".ipynb"):
            notebook_path = os.path.join(root, file)
            with open(notebook_path, "r", encoding="utf-8") as f:
                try:
                    notebook_data = json.load(f)
                except json.JSONDecodeError:
                    continue

                for cell in notebook_data.get("cells", []):
                    if cell.get("cell_type") == "code":
                        cell_source = "".join(cell.get("source", ""))

                        # Get all queries + .format(...) snippets
                        query_format_pairs = extract_sql_statements_in_cell(cell_source)

                        for (stmt, fmt_snippet) in query_format_pairs:
                            # Expand placeholders if we can
                            expanded_stmt = stmt

                            if fmt_snippet:
                                # Try to parse named arguments from the snippet
                                fmt_args = extract_format_arguments(fmt_snippet)
                                if fmt_args:
                                    # Attempt to do the string-format expansion
                                    try:
                                        expanded_stmt = stmt.format(**fmt_args)
                                    except KeyError:
                                        # If placeholders are missing in the dict, keep it unexpanded
                                        pass

                            # Now parse the table name from the (possibly expanded) statement
                            table_name = parse_table_from_query(expanded_stmt)

                            # Count how often we use this table
                            table_frequencies[table_name] += 1

                            # Extract columns and count them for the table
                            cols = parse_columns_from_select(expanded_stmt)
                            for c in cols:
                                column_frequencies[table_name][c] += 1

                            found_queries.append({
                                "notebook": file,
                                "table": table_name,
                                "query": expanded_stmt,
                                "format_piece": fmt_snippet  # store entire .format(...) snippet
                            })

# --------------------------------------------------------------------
# 4. Save Results to Excel
# --------------------------------------------------------------------

if not found_queries:
    print("No SQL queries found in the notebooks.")
    exit()

output_excel_path = "extracted_sql_queries.xlsx"

df_queries = pd.DataFrame(found_queries, columns=["notebook", "table", "query", "format_piece"])

# Table Frequencies
df_table_freq = pd.DataFrame(
    [(tbl, cnt) for tbl, cnt in table_frequencies.items()],
    columns=["table", "count"]
)

# Column Frequencies
table_col_freq_rows = []
for tbl, col_counter in column_frequencies.items():
    for col, col_count in col_counter.items():
        table_col_freq_rows.append({"table": tbl, "column": col, "count": col_count})
df_column_freq = pd.DataFrame(table_col_freq_rows, columns=["table", "column", "count"])

with pd.ExcelWriter(output_excel_path, engine="openpyxl") as writer:
    df_queries.to_excel(writer, sheet_name="SQL Queries", index=False)
    df_table_freq.to_excel(writer, sheet_name="Table Frequencies", index=False)
    df_column_freq.to_excel(writer, sheet_name="Column Frequencies", index=False)

print(f"Extracted SQL queries and frequencies saved to {output_excel_path}")
