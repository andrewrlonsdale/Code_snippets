import pandas as pd
import warnings

# Suppress future warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# Define table, schema, and full table reference
schema_name = "your_schema_name"
table_name = "your_table_name_here"
full_table_name = f"{schema_name}.{table_name}"  # Schema and table name

# Fetch schema information
schema_query = f"""
SELECT column_name, data_type
FROM information_schema.columns
WHERE table_schema = '{schema_name}' AND table_name = '{table_name}'
"""
df_schema = cursor.execute(schema_query).as_pandas()
df_schema['category_type'] = None  # Initialize category type column

# Construct and execute a unified unique count query
unique_count_query = " UNION ALL ".join([
    f"SELECT '{col}' AS column_name, COUNT(DISTINCT {col}) AS unique_count FROM {full_table_name}"
    for col in df_schema['column_name']
])
unique_counts = cursor.execute(unique_count_query).as_pandas()
unique_counts.set_index('column_name', inplace=True)

# Update category types based on data types and unique counts
for index, row in df_schema.iterrows():
    col_name = row['column_name']
    data_type = row['data_type']
    unique_count = unique_counts.loc[col_name, 'unique_count']

    if data_type in ['varchar', 'string'] and unique_count > 100:
        df_schema.at[index, 'category_type'] = 'continuous'
    elif data_type in ['integer', 'bigint', 'date'] and unique_count < 3:
        df_schema.at[index, 'category_type'] = 'categorical'
    else:
        df_schema.at[index, 'category_type'] = 'categorical' if data_type in ['varchar', 'string'] else 'continuous'

# Execute separate queries for each data type and category
results = []
for (data_type, category_type), group in df_schema.groupby(['data_type', 'category_type']):
    if category_type == 'continuous':
        if data_type in ['integer', 'bigint']:
            for col_name in group['column_name']:
                query = f"SELECT '{col_name}' AS field_name, COALESCE(MIN({col_name}), 0) AS min, COALESCE(MAX({col_name}), 0) AS max, 'Not Applicable' AS top_5 FROM {full_table_name}"
                stat = cursor.execute(query).as_pandas()
                results.append(stat)
        else:  # Non-integer data types for continuous variables
            for col_name in group['column_name']:
                query = f"SELECT '{col_name}' AS field_name, MIN({col_name}) AS min, MAX({col_name}) AS max, 'Not Applicable' AS top_5 FROM {full_table_name}"
                stat = cursor.execute(query).as_pandas()
                results.append(stat)
    else:  # Categorical data types
        for col_name in group['column_name']:
            query = f"SELECT '{col_name}' AS field_name, 'Not Applicable' AS min, 'Not Applicable' AS max, ARRAY_TO_STRING(ARRAY_AGG(DISTINCT {col_name} ORDER BY COUNT(*) DESC LIMIT 5), ', ') AS top_5 FROM {full_table_name} GROUP BY {col_name}"
            stat = cursor.execute(query).as_pandas()
            results.append(stat)

# Combine results into a final DataFrame
final_df = pd.concat(results, ignore_index=True)

# Export to CSV
final_df.to_csv('final_schema_statistics.csv', index=False)

# Optionally, print the DataFrame to verify
print(final_df)
