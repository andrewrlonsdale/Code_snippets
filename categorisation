import pandas as pd
from pyathena import connect

# Establishing a connection to Athena
conn = connect(s3_staging_dir="s3://your_s3_staging_directory/",
               region_name='your_region_name')

# Fetch column names and data types
query = """
SELECT column_name, data_type 
FROM information_schema.columns 
WHERE table_schema = 'your_database_name' 
AND table_name = 'your_table_name';
"""

column_data = pd.read_sql(query, conn)

# Placeholder for column categorization
column_types = {}

# Check each column
for index, row in column_data.iterrows():
    column_name = row['column_name']
    data_type = row['data_type']

    # If it's numeric, check unique value count
    if data_type in ['int', 'float', 'double']:  # Adjust this list based on your data types in Athena
        unique_count_query = f"""
        SELECT COUNT(DISTINCT {column_name}) 
        FROM your_database_name.your_table_name;
        """
        
        unique_count = pd.read_sql(unique_count_query, conn).iloc[0, 0]
        
        if unique_count <= 10:
            column_types[column_name] = 'categorical'
        else:
            column_types[column_name] = 'continuous'
    
    # If it's string or other non-numeric type
    else:
        column_types[column_name] = 'categorical'

# Convert to DataFrame for better visualization
df_column_types = pd.DataFrame(list(column_types.items()), columns=['Column', 'Type'])

df_column_types






















import boto3
import time

# Initialize Athena client
athena = boto3.client('athena', region_name='your_region_name')

# Specify the S3 location for query results
output_location = 's3://your_s3_query_results_directory/'

# Start the query execution to fetch column names and data types
response = athena.start_query_execution(
    QueryString="""
    SELECT column_name, data_type 
    FROM information_schema.columns 
    WHERE table_schema = 'your_database_name' 
    AND table_name = 'your_table_name';
    """,
    QueryExecutionContext={
        'Database': 'your_database_name'
    },
    ResultConfiguration={
        'OutputLocation': output_location,
    }
)

# Get the query execution ID
query_execution_id = response['QueryExecutionId']

# Poll Athena until the query completes
while True:
    response = athena.get_query_execution(QueryExecutionId=query_execution_id)
    state = response['QueryExecution']['Status']['State']
    
    if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:
        break
    
    time.sleep(5)  # Wait for 5 seconds before checking again

# If query succeeded, fetch the results
if state == 'SUCCEEDED':
    results = athena.get_query_results(QueryExecutionId=query_execution_id)
    column_data = results['ResultSet']['Rows'][1:]  # Skipping the header row
    column_data = [{'column_name': row['Data'][0]['VarCharValue'], 'data_type': row['Data'][1]['VarCharValue']} for row in column_data]
    column_data_df = pd.DataFrame(column_data)
else:
    print(f"Query failed with state: {state}")
    column_data_df = None

column_data_df










# Placeholder for column details
column_details = []

# Check each column
for index, row in column_data.iterrows():
    column_name = row['column_name']
    data_type = row['data_type']

    # Details for the current column
    column_info = {'Column Name': column_name}

    # If it's numeric, check unique value count
    if data_type in ['int', 'float', 'double']:  # Adjust this list based on your data types in Athena
        unique_count_query = f"""
        SELECT COUNT(DISTINCT {column_name}) 
        FROM your_database_name.your_table_name;
        """
        
        unique_count = pd.read_sql(unique_count_query, conn).iloc[0, 0]
        
        if unique_count <= 10:
            column_info['Type'] = 'categorical'
            
            # Fetch the top 10 values
            top_values_query = f"""
            SELECT {column_name}, COUNT(*) as count 
            FROM your_database_name.your_table_name 
            GROUP BY {column_name} 
            ORDER BY count DESC 
            LIMIT 10;
            """
            
            top_values = pd.read_sql(top_values_query, conn)
            column_info['Top 10 Values'] = ', '.join(map(str, top_values[column_name].tolist()))
            column_info['Min Value'] = None
            column_info['Max Value'] = None
        else:
            column_info['Type'] = 'continuous'
            
            # Fetch min and max values
            min_max_query = f"""
            SELECT MIN({column_name}) as min_value, MAX({column_name}) as max_value
            FROM your_database_name.your_table_name;
            """
            
            min_max_values = pd.read_sql(min_max_query, conn).iloc[0]
            column_info['Min Value'] = min_max_values['min_value']
            column_info['Max Value'] = min_max_values['max_value']
            column_info['Top 10 Values'] = None
    
    # If it's string or other non-numeric type
    else:
        column_info['Type'] = 'categorical'
        
        # Fetch the top 10 values
        top_values_query = f"""
        SELECT {column_name}, COUNT(*) as count 
        FROM your_database_name.your_table_name 
        GROUP BY {column_name} 
        ORDER BY count DESC 
        LIMIT 10;
        """
        
        top_values = pd.read_sql(top_values_query, conn)
        column_info['Top 10 Values'] = ', '.join(map(str, top_values[column_name].tolist()))
        column_info['Min Value'] = None
        column_info['Max Value'] = None
        
    column_details.append(column_info)

# Convert to DataFrame for better visualization
df_column_details = pd.DataFrame(column_details)

df_column_details




import pandas as pd
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor

# Assuming cursor is already initialized and connected to Athena

# Step 1: Fetch unique counts for all columns in one go
count_queries = [f"COUNT(DISTINCT {col}) AS {col}" for col in column_data['column_name']]
count_query = f"""
SELECT
    {', '.join(count_queries)}
FROM
    your_database_name.your_table_name;
"""

unique_counts = cursor.execute(count_query).as_pandas().iloc[0]

# Lists to store columns based on their determined type
continuous_columns = []
categorical_columns = []
high_cardinality_columns = []

# Step 2: Determine column types
for index, row in tqdm(column_data.iterrows(), total=column_data.shape[0], desc="Classifying columns"):
    column_name = row['column_name']
    data_type = row['data_type']
    
    unique_count = unique_counts[column_name]
    
    if data_type in ['int', 'float', 'double'] or 'date' in data_type:
        if 1 < unique_count < 5:
            categorical_columns.append(column_name)
        elif unique_count > 500:
            high_cardinality_columns.append(column_name)
        else:
            continuous_columns.append(column_name)
    elif 'date' not in data_type and unique_count <= 500:
        categorical_columns.append(column_name)
    else:
        high_cardinality_columns.append(column_name)

# Function to fetch min and max for a given column
def fetch_min_max(col):
    query = f"""
    SELECT MIN({col}) AS min_value, MAX({col}) AS max_value
    FROM your_database_name.your_table_name;
    """
    result = cursor.execute(query).as_pandas().iloc[0]
    return col, result['min_value'], result['max_value']

# Function to fetch top 10 values for a given column
def fetch_top_10(col):
    query = f"""
    SELECT {col} AS value, COUNT(*) AS count 
    FROM your_database_name.your_table_name 
    WHERE {col} IS NOT NULL
    GROUP BY {col} 
    ORDER BY count DESC 
    LIMIT 10;
    """
    result = cursor.execute(query).as_pandas()
    return col, result

# Step 3: Parallel fetch min, max for continuous columns and top 10 for categorical columns
column_details = []

with ThreadPoolExecutor() as executor:
    # Fetch min and max values for continuous columns
    for col, min_val, max_val in tqdm(executor.map(fetch_min_max, continuous_columns), total=len(continuous_columns), desc="Fetching min/max values"):
        column_details.append({
            'Column Name': col,
            'SQL Data Type': data_type,
            'Unique Count': unique_counts[col],
            'Type': 'continuous',
            'Min Value': min_val,
            'Max Value': max_val,
            'Top 10 Values': '[Not applicable]'
        })
    
    # Fetch top 10 values for categorical columns
    for col, top_10_df in tqdm(executor.map(fetch_top_10, categorical_columns), total=len(categorical_columns), desc="Fetching top 10 values"):
        top_10_str = ', '.join(map(str, top_10_df['value'].tolist()))
        column_details.append({
            'Column Name': col,
            'SQL Data Type': data_type,
            'Unique Count': unique_counts[col],
            'Type': 'categorical',
            'Min Value': '[Not applicable]',
            'Max Value': '[Not applicable]',
            'Top 10 Values': top_10_str
        })

# Convert to DataFrame for better visualization
df_column_details = pd.DataFrame(column_details)

df_column_details















