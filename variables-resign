import json
import re
import matplotlib.pyplot as plt
import networkx as nx
from collections import defaultdict

# Step 1: Extract Code from Jupyter Notebook
def extract_code_from_notebook(notebook_path):
    """Extracts code cells from a Jupyter notebook"""
    with open(notebook_path, "r", encoding="utf-8") as f:
        notebook = json.load(f)
    
    code_cells = [
        cell["source"] for cell in notebook.get("cells", []) if cell["cell_type"] == "code"
    ]
    return "\n".join(["".join(cell) for cell in code_cells])

# Step 2: Parse Assignments
def parse_assignments(source_code):
    """
    Parses variable assignments and dependencies in the given code.
    
    Returns:
    - assignment_map: { var_name -> [list of its assignments] }
    - dependencies: { var_name -> [list of vars used to create it] }
    """
    assignment_map = defaultdict(list)
    dependencies = defaultdict(list)

    assignment_pattern = re.compile(r"(\w+)\s*=\s*(.+)")
    merge_pattern = re.compile(r"(\w+)\.merge\((\w+)")
    sql_pattern = re.compile(r"(?:pd|spark)\.read_sql\(['\"](.+?)['\"]")
    dataframe_read_pattern = re.compile(r"(?:pd|spark)\.read_(\w+)\((.+?)\)")

    lines = source_code.split("\n")

    for line in lines:
        match = assignment_pattern.match(line)
        if match:
            var_name, expression = match.groups()
            assignment_map[var_name].append(expression.strip())

            # Track dependencies
            var_refs = re.findall(r"(\b\w+\b)", expression)  # Find variable-like references
            dependencies[var_name].extend(var for var in var_refs if var in assignment_map)

            # Check for merge operations
            merge_match = merge_pattern.search(expression)
            if merge_match:
                left_df, right_df = merge_match.groups()
                dependencies[var_name].extend([left_df, right_df])

            # Detect SQL queries
            sql_match = sql_pattern.search(expression)
            if sql_match:
                assignment_map[var_name].append(f"SQL Query: {sql_match.group(1)}")

            # Detect DataFrame file reads
            df_read_match = dataframe_read_pattern.search(expression)
            if df_read_match:
                read_type, source = df_read_match.groups()
                assignment_map[var_name].append(f"File Read ({read_type}): {source}")

    return assignment_map, dependencies

# Step 3: Trace Variable Path
def trace_variable_path(assignment_map, dependencies, target_var):
    """
    Traces the full path of how a target variable was created, step by step.
    
    Returns:
    - List of tracing steps from the original source(s) to the final variable.
    """
    trace_steps = []
    seen_vars = set()
    stack = [(target_var, 0)]  # Stack stores (variable, indentation level)

    while stack:
        current_var, level = stack.pop()
        if current_var in seen_vars:
            continue  # Prevent infinite loops
        seen_vars.add(current_var)

        if current_var in assignment_map:
            last_assignment = assignment_map[current_var][-1]
            trace_steps.append("  " * level + f"{current_var} = {last_assignment}")

            # If SQL or file read, it's a source
            if "SQL Query:" in last_assignment or "File Read" in last_assignment:
                continue  # Stop tracing this branch further

            # Add dependencies (e.g., in case of merges or chained transformations)
            if current_var in dependencies:
                for dep in dependencies[current_var]:
                    stack.append((dep, level + 1))

    return trace_steps[::-1]  # Reverse order to show origin first

# Step 4: Visualize the Flowchart
def visualize_trace_full(trace_steps):
    """
    Visualizes the traced variable dependencies as a flowchart using NetworkX and Matplotlib.
    
    - SQL queries are colored red.
    - File reads are colored orange.
    - DataFrame transformations are colored light blue.
    """
    G = nx.DiGraph()
    node_labels = {}
    node_colors = {}

    prev_node = None

    for step in trace_steps:
        step = step.strip()
        if " = " in step:
            var, expr = step.split(" = ", 1)
            G.add_node(var)
            node_labels[var] = f"{var}\n({expr})"

            # Determine node color
            if "SQL Query:" in expr:
                node_colors[var] = "red"  # SQL Query
            elif "File Read" in expr:
                node_colors[var] = "orange"  # File read
            else:
                node_colors[var] = "lightblue"  # Standard dataframe operation

            if prev_node:
                G.add_edge(var, prev_node)

            prev_node = var

    # Plot the flowchart
    plt.figure(figsize=(12, 7))
    pos = nx.spring_layout(G, seed=42, k=0.6)  # Layout for better visualization
    node_list = list(G.nodes())
    node_color_list = [node_colors[n] for n in node_list]

    nx.draw(G, pos, with_labels=True, node_color=node_color_list, edge_color="gray", 
            node_size=3500, font_size=10, cmap=plt.cm.Paired)
    nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)

    plt.title("Variable Trace Flowchart", fontsize=14)
    plt.show()

# Step 5: Main Function to Run Everything
def trace_and_visualize_variable(notebook_path, variable_to_trace):
    """
    Extracts, parses, traces, and visualizes the full history of a variable.
    
    Args:
    - notebook_path (str): Path to the Jupyter notebook.
    - variable_to_trace (str): The variable to trace back.
    """
    # Extract and parse notebook code
    source_code = extract_code_from_notebook(notebook_path)
    assignment_map, dependencies = parse_assignments(source_code)

    # Get full trace
    trace_steps = trace_variable_path(assignment_map, dependencies, variable_to_trace)

    # Display results as a flowchart
    print("\nTracing Path for Variable:", variable_to_trace)
    for step in trace_steps:
        print(step)

    # Visualize as a flowchart
    visualize_trace_full(trace_steps)

# Example usage (replace with actual notebook path and variable)
notebook_path = "your_notebook.ipynb"
variable_to_trace = "df_2"
trace_and_visualize_variable(notebook_path, variable_to_trace)
